{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc19593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face verification with the VGGFace2 model\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "import pandas as pd\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "    # load image from file\n",
    "    print(filename)\n",
    "    pixels = pyplot.imread(filename)\n",
    "    pyplot.imshow(pixels)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    print(results)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    return face_array\n",
    "\n",
    "model = None\n",
    "# extract faces and calculate face embeddings for a list of photo files\n",
    "def get_embeddings(filenames):\n",
    "    # extract faces\n",
    "    faces = [extract_face(f) for f in filenames]\n",
    "    # convert into an array of samples\n",
    "    samples = asarray(faces, 'float32')\n",
    "    # prepare the face for the model, e.g. center pixels\n",
    "    samples = preprocess_input(samples, version=2)\n",
    "    # create a vggface model\n",
    "    global model\n",
    "    if not model:\n",
    "        model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "    # perform prediction\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat\n",
    "\n",
    "# determine if a candidate face is a match for a known face\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "    # calculate distance between embeddings\n",
    "    score = cosine(known_embedding, candidate_embedding)\n",
    "    if score <= thresh:\n",
    "        print('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
    "        return True, score\n",
    "    else:\n",
    "        print('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
    "        return False, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64c39735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"data\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def extract_face2(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_locations = detector(gray, 1)\n",
    "    return face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e3ffa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "554cc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78dff1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = pathlib.Path('../data/mfr2')\n",
    "labels_path = BASE_PATH / 'mfr2_labels.txt'\n",
    "pairs_path = BASE_PATH / 'pairs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f10eb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.read_csv(filepath_or_buffer=str(labels_path))\n",
    "labels=labels.apply(lambda x: x.apply(lambda y: y.strip() if type(y) == type('') else y), axis=0)\n",
    "people=labels[\"person\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3de0235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>index</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdrianDunbar</td>\n",
       "      <td>2</td>\n",
       "      <td>no-mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdrianDunbar</td>\n",
       "      <td>4</td>\n",
       "      <td>no-mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  index     mask\n",
       "1  AdrianDunbar      2  no-mask\n",
       "3  AdrianDunbar      4  no-mask"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[(labels[\"person\"]==people[0]) & (labels[\"mask\"]==\"no-mask\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22b00af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labels[(labels[\"person\"]==people[0]) & (labels[\"mask\"]==\"no-mask\")][\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc97cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(person, mask=True):\n",
    "    if mask:\n",
    "        mask_filter = labels[\"mask\"]!=\"no-mask\"\n",
    "    else:\n",
    "        mask_filter = labels[\"mask\"]==\"no-mask\"\n",
    "    person_filter = labels[\"person\"]==person\n",
    "    return list(labels[person_filter & mask_filter][\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff67c2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_indexes(people[0],mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4573aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs={person:list(zip(get_indexes(person,mask=True), get_indexes(person, mask=False))) for person in people}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91f76362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(p) for p in pairs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b970ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "person, pairs = list(pairs.items())[0]\n",
    "index1, index2 = pairs[0]\n",
    "path1 = BASE_PATH / person / f'{person}_{str(index1).rjust(4, \"0\")}.png'\n",
    "path2 = BASE_PATH / person / f'{person}_{str(index2).rjust(4, \"0\")}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4829f8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rectangles[[(26, 46) (116, 136)]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract_face2(str(path1))\n",
    "extract_face2(str(path2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c72fc47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'person1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5232/2116511078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mperson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mpath1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBASE_PATH\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mperson1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mf'{person}_{str(index1).rjust(4, \"0\")}.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mpath2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBASE_PATH\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mperson2\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mf'{person}_{str(index2).rjust(4, \"0\")}.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'person1' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# positive test\n",
    "for person, pairs in pairs.items():\n",
    "    for index1, index2 in pairs:\n",
    "        path1 = BASE_PATH / person / f'{person}_{str(index1).rjust(4, \"0\")}.png'\n",
    "        path2 = BASE_PATH / person / f'{person}_{str(index2).rjust(4, \"0\")}.png'\n",
    "\n",
    "        features1,features2=get_embeddings([path1, path2])\n",
    "        matched, distance = is_match(features1, features2)\n",
    "\n",
    "        results.append([pair, matched, distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=len([x for x in results if x[1]]) / len(results)\n",
    "FN=1-TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e35911",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(BASE_PATH.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e746ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_neg = []\n",
    "count = 0\n",
    "\n",
    "for person1 in BASE_PATH.iterdir():\n",
    "    for person2 in BASE_PATH.iterdir():\n",
    "        if not person1.is_dir() or not person2.is_dir() or person1.name == person2.name or not person1.name.isalpha() or not person2.name.isalpha():\n",
    "            continue\n",
    "        count += 1\n",
    "        if count >= len(results):\n",
    "            break\n",
    "        index1 = index2 = 1\n",
    "        \n",
    "        path1 = BASE_PATH / person1.name / f'{person1.name}_{str(index1).rjust(4, \"0\")}.png'\n",
    "        path2 = BASE_PATH / person2.name / f'{person2.name}_{str(index2).rjust(4, \"0\")}.png'\n",
    "\n",
    "        try:\n",
    "            features1,features2=get_embeddings([path1, path2])\n",
    "            matched, distance = is_match(features1, features2)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        results_neg.append([pair, matched, distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ecad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP=len([x for x in results_neg if x[1]]) / len(results_neg)\n",
    "TN=1-FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd915380",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=len([x for x in results if x[1]]) / (len(results) + len(results_neg))\n",
    "FN=len([x for x in results if not x[1]]) / (len(results) + len(results_neg))\n",
    "FP=len([x for x in results_neg if x[1]]) / (len(results) + len(results_neg))\n",
    "TN=len([x for x in results_neg if not x[1]]) / (len(results) + len(results_neg))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = [[TP,FN],\n",
    "         [FP,TN]]\n",
    "\n",
    "df_cm = pd.DataFrame(array, ['same', 'different'], ['verified', 'unverified'])\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3897a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "X = [x[2] for x in results] + [x[2] for x in results_neg]\n",
    "y = [1 for x in results] + [0 for x in results_neg]\n",
    "clf = svm.SVC()\n",
    "clf.fit(np.array(X).reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a052ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=clf.predict(np.array([x[2] for x in results]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in ps if x == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns=clf.predict(np.array([x[2] for x in results_neg]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([x[2] for x in results + results_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in ps if x == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c533a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=len([x for x in ps if x]) / (len(results) + len(results_neg))\n",
    "FN=len([x for x in ps if not x]) / (len(results) + len(results_neg))\n",
    "FP=len([x for x in ns if x]) / (len(results) + len(results_neg))\n",
    "TN=len([x for x in ns if not x]) / (len(results) + len(results_neg))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = [[TP,FN],\n",
    "         [FP,TN]]\n",
    "\n",
    "df_cm = pd.DataFrame(array, ['same', 'different'], ['verified', 'unverified'])\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c23ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ab3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results) + len(results_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29c734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embeddings([r\"D:\\self\\university\\workshop\\project\\data\\mfr2\\AdrianDunbar\\AdrianDunbar_0002.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embeddings([r\"D:\\self\\university\\workshop\\project\\MaskedFaceDetection\\data\\Nicolas_Cage_unmasked1.jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68620414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
